# What is the load factor in HashMap?
The load factor in a HashMap is a measure that determines when to increase the capacity of the HashMap to maintain its performance. It is defined as the ratio of the number of elements (entries) in the HashMap to the total number of buckets (capacity) available in the HashMap. The load factor is represented as a float value, typically ranging from 0.0 to 1.0.
By default, the load factor for a HashMap in Java is set to 0.75. This means that when the number of entries in the HashMap exceeds 75% of its capacity, the HashMap will automatically resize itself (usually by doubling its capacity) to reduce the likelihood of collisions and maintain efficient access times.
A higher load factor (closer to 1.0) can lead to more collisions and slower access times, while a lower load factor (closer to 0.0) can lead to increased memory usage due to more frequent resizing. Therefore, the default load factor of 0.75 is a good compromise between time and space efficiency for most applications.
